{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":82,"metadata":{"id":"BklfbsliyrMs","executionInfo":{"status":"ok","timestamp":1700506957009,"user_tz":-330,"elapsed":414,"user":{"displayName":"Pranav Parkale","userId":"09188510687728247183"}},"outputId":"17fb9744-464d-414d-9896-63d4c753ae36","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Hello World!\n"]}],"source":["print(\"Hello World!\")"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"3MgECd6byvZp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700506960600,"user_tz":-330,"elapsed":3185,"user":{"displayName":"Pranav Parkale","userId":"09188510687728247183"}},"outputId":"b5991da3-675c-4c17-9162-c4b324c4585b"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["pip install PyPDF2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h_TGpRAPzKKm","executionInfo":{"status":"ok","timestamp":1700506968938,"user_tz":-330,"elapsed":8344,"user":{"displayName":"Pranav Parkale","userId":"09188510687728247183"}},"outputId":"135fa0f8-23aa-47f1-f341-81ba6f79a6ed"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"]}]},{"cell_type":"code","source":["import PyPDF2\n","import os\n","import json\n","\n","def pdf_to_json(pdf_path):\n","    \"\"\"Converts the content of a PDF to JSON format.\"\"\"\n","    content = {}\n","\n","    with open(pdf_path, 'rb') as pdf_file:\n","        reader = PyPDF2.PdfReader(pdf_file)\n","        for page_num in range(len(reader.pages)):\n","            page = reader.pages[page_num]\n","            content[f\"page_{page_num + 1}\"] = page.extract_text()\n","\n","    return content\n","\n","def save_as_json(data, output_path):\n","    \"\"\"Saves data to a JSON file.\"\"\"\n","    with open(output_path, 'w', encoding='utf-8') as json_file:\n","        json.dump(data, json_file, ensure_ascii=False, indent=4)\n","\n","if __name__ == \"__main__\":\n","    folder_path = \"/content/drive/My Drive/BEProjectColab/Resumes\"\n","    output_folder = \"/content/drive/My Drive/BEProjectColab/ResumesJSON\"\n","\n","    os.makedirs(output_folder, exist_ok=True)\n","\n","    for file in os.listdir(folder_path):\n","        if file.endswith(\".pdf\"):\n","            pdf_path = os.path.join(folder_path, file)\n","            json_content = pdf_to_json(pdf_path)\n","\n","            output_filename = os.path.splitext(file)[0] + \".json\"\n","            output_path = os.path.join(output_folder, output_filename)\n","            save_as_json(json_content, output_path)\n","\n","    print(\"Conversion complete!\")\n","    print(json_content)"],"metadata":{"id":"6-hWSy06zeZ9","executionInfo":{"status":"ok","timestamp":1700506968939,"user_tz":-330,"elapsed":12,"user":{"displayName":"Pranav Parkale","userId":"09188510687728247183"}},"outputId":"e738e841-eafb-4a89-ceae-8ed9c71faba6","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["Conversion complete!\n","{'page_1': 'Sourabh Bajaj Email : mail@website.com\\nhttp://www.sourabhbajaj.com Mobile : +1-123-456-7890\\nEducation\\n•Georgia Institute of Technology Atlanta, GA\\nMaster of Science in Computer Science; GPA: 4.00 Aug. 2012 – Dec. 2013\\n•Birla Institute of Technology and Science Pilani, India\\nBachelor of Engineering in Electrical and Electronics; GPA: 3.66 (9.15/10.0) Aug. 2008 – July. 2012\\nExperience\\n•Google Mountain View, CA\\nSoftware Engineer Oct 2016 - Present\\n◦Tensorflow : TensorFlow is an open source software library for numerical computation using data flow graphs;\\nprimarily used for training deep learning models.\\n◦Apache Beam : Apache Beam is a unified model for defining both batch and streaming data-parallel processing\\npipelines, as well as a set of language-specific SDKs for constructing pipelines and runners.\\n•Coursera Mountain View, CA\\nSenior Software Engineer Jan 2014 - Oct 2016\\n◦Notifications : Service for sending email, push and in-app notifications. Involved in features such as delivery time\\noptimization, tracking, queuing and A/B testing. Built an internal app to run batch campaigns for marketing etc.\\n◦Nostos : Bulk data processing and injection service from Hadoop to Cassandra and provides a thin REST layer on\\ntop for serving offline computed data online.\\n◦Workflows : Dataduct an open source workflow framework to create and manage data pipelines leveraging\\nreusables patterns to expedite developer productivity.\\n◦Data Collection : Designed the internal survey and crowd sourcing platfowm which allowed for creating various\\ntasks for crowd sourding or embedding surveys across the Coursera platform.\\n◦Dev Environment : Analytics environment based on docker and AWS, standardized the python and R\\ndependencies. Wrote the core libraries that are shared by all data scientists.\\n◦Data Warehousing : Setup, schema design and management of Amazon Redshift. Built an internal app for access\\nto the data using a web interface. Dataduct integration for daily ETL injection into Redshift.\\n◦Recommendations : Core service for all recommendation systems at Coursesa, currently used on the homepage\\nand throughout the content discovery process. Worked on both offline training and online serving.\\n◦Content Discovery : Improved content discovery by building a new onboarding experience on coursera. Using this\\nto personalize the search and browse experience. Also worked on ranking and indexing improvements.\\n◦Course Dashboards : Instructor dashboards and learner surveying tools, which helped instructors run their class\\nbetter by providing data on Assignments and Learner Activity.\\n•Lucena Research Atlanta, GA\\nData Scientist Summer 2012 and 2013\\n◦Portfolio Management : Created models for portfolio hedging, portfolio optimization and price forecasting. Also\\ncreating a strategy backtesting engine used for simulating and backtesting strategies.\\n◦QuantDesk : Python backend for a web application used by hedge fund managers for portfolio management.\\nProjects\\n•QuantSoftware Toolkit : Open source python library for financial data analysis and machine learning for finance.\\n•Github Visualization : Data Visualization of Git Log data using D3 to analyze project trends over time.\\n•Recommendation System : Music and Movie recommender systems using collaborative filtering on public datasets.\\nProgramming Skills\\n•Languages : Scala, Python, Javascript, C++, SQL, Java Technologies : AWS, Play, React, Kafka, GCE'}\n"]}]},{"cell_type":"code","source":["pip install nltk"],"metadata":{"id":"DQkVrExg1MDZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700506986190,"user_tz":-330,"elapsed":11504,"user":{"displayName":"Pranav Parkale","userId":"09188510687728247183"}},"outputId":"e53c8975-c91b-4172-b1cb-93fc1fa3d02a"},"execution_count":86,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"]}]},{"cell_type":"code","source":["import nltk\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p8L5CxXn13OW","executionInfo":{"status":"ok","timestamp":1700506986191,"user_tz":-330,"elapsed":28,"user":{"displayName":"Pranav Parkale","userId":"09188510687728247183"}},"outputId":"f4feae3c-5ef8-41c5-b26e-0c6011000e2d"},"execution_count":87,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":87}]},{"cell_type":"code","source":["import json\n","import os\n","import string\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize\n","\n","# Initialize lemmatizer and stopwords\n","lemmatizer = WordNetLemmatizer()\n","stop_words = set(stopwords.words('english'))\n","\n","def preprocess_text(text):\n","    # Convert to lowercase\n","    text = text.lower()\n","\n","    # Tokenize\n","    tokens = word_tokenize(text)\n","\n","    # Remove '•, ◦'\n","    text = text.replace('•', '')\n","    text = text.replace('◦', '')\n","\n","    # Remove punctuation and stopwords, and lemmatize\n","    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and word not in string.punctuation]\n","\n","    # Rejoin words after preprocessing\n","    return ' '.join(tokens)\n","\n","def preprocess_json_file(json_file_path, preprocessed_folder_path):\n","    with open(json_file_path, 'r', encoding='utf-8') as file:\n","        data = json.load(file)\n","\n","    # Check if the data is a dictionary or a list and preprocess accordingly\n","    if isinstance(data, dict):\n","        for key, value in data.items():\n","            if isinstance(value, str):  # Ensure we're working with strings\n","                data[key] = preprocess_text(value)\n","    elif isinstance(data, list):\n","        data = [preprocess_text(text) for text in data if isinstance(text, str)]\n","    else:\n","        # If the data is not a dictionary or list, we won't process it\n","        return\n","\n","    # Create filename for the preprocessed data\n","    base_name = os.path.basename(json_file_path)\n","    preprocessed_json_path = os.path.join(preprocessed_folder_path, base_name)\n","\n","    with open(preprocessed_json_path, 'w', encoding='utf-8') as file:\n","        json.dump(data, file, ensure_ascii=False, indent=4)\n","\n","\n","if __name__ == \"__main__\":\n","    folder_path = \"/content/drive/My Drive/BEProjectColab/ResumesJSON\"\n","    preprocessed_folder_path = os.path.join(folder_path, \"Preprocessed\")\n","\n","    # Create the Preprocessed folder if it doesn't exist\n","    os.makedirs(preprocessed_folder_path, exist_ok=True)\n","\n","    for file in os.listdir(folder_path):\n","        if file.endswith(\".json\"):\n","            json_path = os.path.join(folder_path, file)\n","            preprocess_json_file(json_path, preprocessed_folder_path)\n","\n","    print(\"Preprocessing complete!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"que0g17215iz","executionInfo":{"status":"ok","timestamp":1700507032743,"user_tz":-330,"elapsed":639,"user":{"displayName":"Pranav Parkale","userId":"09188510687728247183"}},"outputId":"4a77be1f-659a-4043-99d5-02f11785990b"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":["Preprocessing complete!\n"]}]},{"cell_type":"code","source":["pip install scikit-learn nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dFlfbwAh19Qv","executionInfo":{"status":"ok","timestamp":1700507040907,"user_tz":-330,"elapsed":7749,"user":{"displayName":"Pranav Parkale","userId":"09188510687728247183"}},"outputId":"f9702bb9-a0aa-49a1-efce-5c3c043056d2"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.3)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"]}]},{"cell_type":"code","source":["pip install spacy"],"metadata":{"id":"ojh3ejkiHIIG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700507049105,"user_tz":-330,"elapsed":8210,"user":{"displayName":"Pranav Parkale","userId":"09188510687728247183"}},"outputId":"24493959-f378-41b0-9019-c34654ba7f27"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.3)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.3)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n"]}]},{"cell_type":"code","source":["!python -m spacy download en_core_web_sm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_S00Iv7YFptq","executionInfo":{"status":"ok","timestamp":1700507077899,"user_tz":-330,"elapsed":28800,"user":{"displayName":"Pranav Parkale","userId":"09188510687728247183"}},"outputId":"2e66591e-da11-4b9f-b873-58f6c34a92c7"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-11-20 19:04:12.599372: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-20 19:04:12.599434: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-20 19:04:12.599476: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-20 19:04:13.846666: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Collecting en-core-web-sm==3.6.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.10)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.3)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.13)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.7.22)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.3)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n"]}]},{"cell_type":"code","source":["import json\n","import os\n","import spacy\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Load the spaCy model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","def load_preprocessed_data(json_file_path):\n","    \"\"\"Load and concatenate content from JSON file.\"\"\"\n","    with open(json_file_path, 'r', encoding='utf-8') as file:\n","        data = json.load(file)\n","    if isinstance(data, dict):\n","        return ' '.join(data.values())\n","    elif isinstance(data, list):\n","        return ' '.join(data)\n","    else:\n","        return data\n","\n","def spacy_tokenizer(document):\n","    \"\"\"Tokenize, lemmatize and filter out stopwords using spaCy.\"\"\"\n","    tokens = nlp(document)\n","    return [token.lemma_ for token in tokens if not token.is_stop and not token.is_punct]\n","\n","def extract_top_keywords_with_spacy(folder_path, n_keywords=10):\n","    \"\"\"Extract top-N keywords from all documents in a directory using spaCy and TF-IDF.\"\"\"\n","\n","    documents = []\n","\n","    for file in os.listdir(folder_path):\n","        if file.endswith(\".json\"):\n","            json_path = os.path.join(folder_path, file)\n","            documents.append(load_preprocessed_data(json_path))\n","\n","    if not documents:\n","        return []\n","\n","    vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer)\n","    tfidf_matrix = vectorizer.fit_transform(documents)\n","\n","    feature_names = vectorizer.get_feature_names_out()\n","    sorted_indices = tfidf_matrix.sum(axis=0).argsort()[0, -n_keywords:].tolist()[0]\n","    # top_keywords = [feature_names[i] for i in reversed(sorted_indices)]\n","    top_keywords = [feature_names[i] for i in sorted_indices]\n","\n","    return top_keywords\n","\n","if __name__ == \"__main__\":\n","    folder_path = \"/content/drive/My Drive/BEProjectColab/ResumesJSON/Preprocessed\"\n","    keywords = extract_top_keywords_with_spacy(folder_path, n_keywords=20)\n","    print(keywords)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e74F-Pn1GZSV","executionInfo":{"status":"ok","timestamp":1700507348111,"user_tz":-330,"elapsed":2367,"user":{"displayName":"Pranav Parkale","userId":"09188510687728247183"}},"outputId":"97b985e9-d408-40f7-e65a-78933d79fec2"},"execution_count":99,"outputs":[{"output_type":"stream","name":"stdout","text":["['pipeline', 'discovery', 'content', 'app', 'management', 'science', 'model', 'service', 'library', 'software', 'experience', 'system', 'build', 'source', 'python', 'create', 'portfolio', 'data', 'datum', '◦']\n"]}]},{"cell_type":"code","source":["print(\"That's it for Stage 1\")"],"metadata":{"id":"N5sNUcyR33rc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700507462389,"user_tz":-330,"elapsed":424,"user":{"displayName":"Pranav Parkale","userId":"09188510687728247183"}},"outputId":"258d5e1a-c420-4ef1-e532-eb512a4a255b"},"execution_count":100,"outputs":[{"output_type":"stream","name":"stdout","text":["That's it for Stage 1\n"]}]}]}